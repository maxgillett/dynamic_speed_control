{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "closed-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, itertools\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from numba import jit, njit, prange\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b2550b-6192-4560-9c5d-74c71226a87a",
   "metadata": {},
   "source": [
    "## Routines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4f889c-9b5a-4bfa-a36c-89793805031a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Learning rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29dea6af-672a-44a6-94b2-0327c9f4119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BilinearPlasticityRule:\n",
    "    def __init__(self):\n",
    "        self.f = lambda x:x\n",
    "        self.g = lambda x:x\n",
    "        \n",
    "class ThresholdPlasticityRule:\n",
    "    def __init__(self,\n",
    "            x_f,\n",
    "            q_f,\n",
    "            x_g=None,\n",
    "            q_g=None,\n",
    "            rv=norm):\n",
    "        if not x_g: x_g = x_f\n",
    "        if not q_g: q_g = rv.cdf(x_g)\n",
    "        self.x_f, self.q_f = x_f, q_f\n",
    "        self.x_g, self.q_g = x_g, q_g\n",
    "        def f(x):\n",
    "            return np.where(x > x_f, q_f, -(1-q_f))\n",
    "        def g(x):\n",
    "            return np.where(x > x_g, q_g, -(1-q_g))\n",
    "        self.f = f\n",
    "        self.g = g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0854813f-9d6b-438f-9aee-778c50f909a3",
   "metadata": {},
   "source": [
    "#### Structural connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eede2a15-3cd8-42c0-9307-0636e5d0eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ji(k, N):\n",
    "    ji = []\n",
    "    arr = np.arange(N)\n",
    "    for i in trange(N):\n",
    "        tmp = np.concatenate((arr[:i], arr[i+1:]))\n",
    "        j_subset = np.random.choice(N, size=k[i], replace=False)\n",
    "        ji.append(np.asarray(sorted(j_subset)))\n",
    "    return ji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55926b4-2b1c-4436-aa83-c14bc192eafc",
   "metadata": {},
   "source": [
    "#### Storing associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0e3dcdb-e222-4d55-94a5-17116f483c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(seq, p, f, g, i, j):\n",
    "    \"$f(xi_i^{\\mu+p}) * g(xi_j^{\\mu})$\"\n",
    "    if p == 0:\n",
    "        return np.sum(f(seq[:,i][:,np.newaxis]) * g(seq[:,j]), axis=0)\n",
    "    else:\n",
    "        return np.sum(f(seq[p:,i][:,np.newaxis]) * g(seq[:-p,j]), axis=0)\n",
    "\n",
    "def store_associations(seq, f, g, ji, K, p=1):\n",
    "    \"outputs in csr representation\"\n",
    "    N = len(ji)\n",
    "    indptr = np.asarray([0]+[len(ji[i]) for i in range(N)]).cumsum()\n",
    "    indices = np.concatenate(ji)\n",
    "    data = []\n",
    "    for i in trange(N):\n",
    "        j = ji[i]\n",
    "        w = np.asarray(weight(seq, p, f, g, i, j) / K, np.float32)\n",
    "        data.extend(w)\n",
    "    return indptr, indices, data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941c3eb3-2793-4703-9240-09028899779a",
   "metadata": {},
   "source": [
    "#### Partition into subpopulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d8c902b-8b66-4bc8-b68d-026614ab0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweight(data, A, N, w_11, w_12, w_21, w_22):\n",
    "    N1 = int(N/2)\n",
    "    for n, (idx_0, idx_1) in tqdm(enumerate(zip(indptr[:N], indptr[1:N+1]))):\n",
    "        idxs = indices[idx_0:idx_1]\n",
    "        idx_m = idx_0 + idxs[idxs < N1].size\n",
    "        if n < N1:\n",
    "            data[idx_0:idx_m] *= A*w_11\n",
    "            data[idx_m:idx_1] *= A*w_12\n",
    "        else:\n",
    "            data[idx_0:idx_m] *= A*w_21\n",
    "            data[idx_m:idx_1] *= A*w_22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e243f72f-cb18-4a60-be86-14172927a1ef",
   "metadata": {},
   "source": [
    "#### Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67915e84-c7a4-49ab-bede-0c120e9275a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erf(x):\n",
    "    z = abs(x)\n",
    "    t = 1.0/(1.0+0.5*z)\n",
    "    ans = t*cp.exp(-z*z-1.26551223+t*(1.00002368+t*(0.37409196+t*(0.09678418+ \\\n",
    "        t*(-0.18628806+t*(0.27886807+t*(-1.13520398+t*(1.48851587+ \\\n",
    "        t*(-0.82215223+t*0.17087277)))))))))\n",
    "    return 1 - cp.where(x > 0, ans, 2.0-ans)\n",
    "\n",
    "def phi(x, theta, sigma):\n",
    "    return 0.5 * (1 + erf((x - theta) / (cp.sqrt(2) * sigma)))\n",
    "\n",
    "def simulate_euler(t0, T, dt, tau, r0, W, theta, sigma, I_ext=lambda x: 0, disable_pbar=False):\n",
    "    \"$\\frac{dx}{dt} = -x + \\phi( \\sum_{j} J_{ij} x_j + I_0 )$\"\n",
    "    state = cp.zeros((N, int((T-t0)/dt)))\n",
    "    state[:,0] = r0\n",
    "    for i, t in enumerate(tqdm(np.arange(t0,T-dt,dt), disable=disable_pbar)):\n",
    "        r = state[:,i]\n",
    "        r_sum = W.dot(r) + I_ext(t)\n",
    "        dr = (-r + phi(r_sum, theta, sigma)) / tau\n",
    "        state[:,i+1] = r + dt * dr\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cb72c7f-2ff8-4f93-a4a4-7585138bda07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(T, dt, tau, I_ext_1, I_ext_2, theta, sigma, patterns, W, disable_pbar=False):\n",
    "    def I_ext(t):\n",
    "        return cp.concatenate((\n",
    "            cp.full(shape=(int(N/2)), fill_value=I_ext_1, dtype=cp.float32), # -0.8\n",
    "            cp.full(shape=(int(N/2)), fill_value=I_ext_2, dtype=cp.float32))) # 0\n",
    "        \n",
    "    r0=phi(cp.asarray(patterns[0,:]), theta, sigma)\n",
    "        \n",
    "    r = simulate_euler(\n",
    "        0, T, dt,\n",
    "        tau,\n",
    "        r0,\n",
    "        W,\n",
    "        theta, sigma,\n",
    "        I_ext,\n",
    "        disable_pbar)\n",
    "    return r.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2680913e-f8a6-4d03-837e-c5804b6d1368",
   "metadata": {},
   "source": [
    "#### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ff8cbbb-f086-4feb-b9e9-6a8284260c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = cp\n",
    "def correlations(r, patterns, individual=False):\n",
    "    \"Assumes populations of equal size\"\n",
    "    P, N, T = patterns.shape[0], r.shape[0], r.shape[1]\n",
    "    n1 = int(N/2)\n",
    "    n2 = int(N/2)\n",
    "    r = xp.asarray(r)\n",
    "    q = xp.zeros(shape=(P,T)) \n",
    "    q1 = xp.zeros(shape=(P,T))\n",
    "    q2 = xp.zeros(shape=(P,T))\n",
    "    for u, pattern in enumerate(xp.asarray(patterns)):\n",
    "        # q: Correlation of whole population\n",
    "        pattern_mean = pattern.mean()\n",
    "        pattern_std = xp.sqrt(xp.sum((pattern-pattern_mean)**2))\n",
    "        for t in range(T):\n",
    "            q[u,t] = xp.sum((pattern - pattern_mean) * (r[:,t] - r[:,t].mean())) / \\\n",
    "                xp.sqrt(xp.sum((r[:,t]-r[:,t].mean())**2)) / \\\n",
    "                pattern_std\n",
    "        if individual:\n",
    "            # q_1: Population 1 correlations\n",
    "            pattern_mean = pattern[:n1].mean()\n",
    "            pattern_std = xp.sqrt(xp.sum((pattern[:n1]-pattern_mean)**2))\n",
    "            for t in range(T):\n",
    "                q1[u,t] = xp.sum((pattern[:n1] - pattern_mean) * (r[:n1,t] - r[:n2,t].mean())) / \\\n",
    "                    xp.sqrt(xp.sum((r[:n1,t]-r[:n1,t].mean())**2)) / \\\n",
    "                    pattern_std\n",
    "            # q_2: Population 2 correlations\n",
    "            pattern_mean = pattern[n1:].mean()\n",
    "            pattern_std = xp.sqrt(xp.sum((pattern[n1:]-pattern_mean)**2))\n",
    "            for t in range(T):\n",
    "                q2[u,t] = xp.sum((pattern[n1:] - pattern_mean) * (r[n1:,t] - r[n1:,t].mean())) / \\\n",
    "                    xp.sqrt(xp.sum((r[n1:,t]-r[n1:,t].mean())**2)) / \\\n",
    "                    pattern_std\n",
    "    return q.get(), q1.get(), q2.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08041bde-29c1-463c-a53c-02a00746f208",
   "metadata": {},
   "source": [
    "## Figure data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3355715-ec12-41db-86f1-e7cbdbe90916",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 80000\n",
    "p = 0.005\n",
    "K = N*p\n",
    "P = 16\n",
    "tau = 0.01\n",
    "dt = 1e-3\n",
    "\n",
    "A = 20\n",
    "theta = 0\n",
    "sigma = 0.05\n",
    "x_f = 1.5\n",
    "q_f = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9df91a10-10a6-495b-8bf3-05fd3b5ec0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = np.random.RandomState(seed=1).normal(0,1,size=(P,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06fd5010-689b-4f47-815b-4d3395c6f676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80000/80000 [01:47<00:00, 746.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Structural connectivity\n",
    "k = np.random.RandomState(seed=2).binomial(N, p, size=N)\n",
    "k[:] = 400 # fixed degree\n",
    "ji = build_ji(k, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e5c7033-03ee-4e28-a8d0-e55ef803d78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80000/80000 [00:07<00:00, 10163.67it/s]\n",
      "100%|██████████| 80000/80000 [00:07<00:00, 10578.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Store pattern associations using the threshold plasticity rule\n",
    "plasticity = ThresholdPlasticityRule(x_f, q_f)\n",
    "indptr, indices, data_p0 = store_associations(\n",
    "    patterns, plasticity.f, plasticity.g, ji, K, p=0)\n",
    "_, _, data_p1 = store_associations(\n",
    "    patterns, plasticity.f, plasticity.g, ji, K, p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "346cee39-fafa-4adc-b17f-1fe05a8c4b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80000it [00:00, 147606.66it/s]\n",
      "80000it [00:00, 148345.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Adjust subpopulation weights\n",
    "data_p1_copy = np.asarray(data_p1).copy()\n",
    "data_p0_copy = np.asarray(data_p0).copy()\n",
    "reweight(data_p1_copy, \n",
    "         A, N, w_11=1, w_12=1, w_21=0, w_22=0)\n",
    "reweight(data_p0_copy,\n",
    "         A, N, w_11=0, w_12=0, w_21=1, w_22=1)\n",
    "data = data_p1_copy + data_p0_copy\n",
    "W = cp.sparse.csr_matrix(\n",
    "    (cp.asarray(data), cp.asarray(indices), cp.asarray(indptr)),\n",
    "    shape=(N,N),\n",
    "    dtype=cp.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cdf92a-e709-4ac0-8324-c894cad868d6",
   "metadata": {},
   "source": [
    "### Simulation runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db05844-deee-4231-bee8-581910fdf31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 201/560 [1:46:36<3:08:49, 31.56s/it]"
     ]
    }
   ],
   "source": [
    "I_ext_1=np.arange(-0.6,-0.8,-0.6/39)[::-1]\n",
    "I_ext_2=np.linspace(-0.4,0.,40)\n",
    "\n",
    "params = {\n",
    "    \"N\": N,\n",
    "    \"p\": p,\n",
    "    \"K\": K,\n",
    "    \"P\": P,\n",
    "    \"A\": A,\n",
    "    \"tau\": tau,\n",
    "    \"theta\": theta,\n",
    "    \"sigma\": sigma,\n",
    "    \"x_f\": plasticity.x_f,\n",
    "    \"q_f\": plasticity.q_f,\n",
    "    \"x_g\": plasticity.x_g,\n",
    "    \"q_g\": plasticity.q_g,\n",
    "}\n",
    "\n",
    "combinations = list(itertools.product(\n",
    "    np.atleast_1d(I_ext_1),\n",
    "    np.atleast_1d(I_ext_2)))\n",
    "\n",
    "directory = \"3-nonlinear-phase-diagram/data/\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(directory)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "for args in tqdm(combinations[:]):\n",
    "    params[\"I_ext_1\"] = I_ext_1 = args[0]\n",
    "    params[\"I_ext_2\"] = I_ext_2 = args[1]\n",
    "    \n",
    "    r = simulate(\n",
    "        2.0,  # T\n",
    "        1e-3, # dt\n",
    "        0.01, # tau\n",
    "        I_ext_1,\n",
    "        I_ext_2,\n",
    "        theta,\n",
    "        sigma,\n",
    "        patterns,\n",
    "        W,\n",
    "        disable_pbar=True)\n",
    "    q, q1, q2 = correlations(r, patterns, individual=True)\n",
    "    filename = \"Iext1%.6f_Iext2%.6f\"%(I_ext_1,I_ext_2) + \".npy\"\n",
    "    filepath = directory + filename\n",
    "    np.save(open(filepath, 'wb'), {\n",
    "        \"q\": q,\n",
    "        \"q1\": q1,\n",
    "        \"q2\": q2,\n",
    "        \"params\": params})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7733a-3e13-4fc4-b9c6-35e653ee0aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
